{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3601f595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dotenv.exe is installed in 'C:\\Users\\jahna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\jahna\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe184f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!{sys.executable} -m pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819171d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jahna\\OneDrive\\Desktop\\eeg+mri\\EpilepsyNexus\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f68982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-groq\n",
      "  Using cached langchain_groq-1.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
      "  Using cached groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.2.8 (from langchain-groq)\n",
      "  Using cached langchain_core-1.2.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting sniffio (from groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Using cached langsmith-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.8->langchain-groq) (26.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Using cached tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Using cached uuid_utils-0.14.0-cp39-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Downloading orjson-3.11.7-cp311-cp311-win_amd64.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.1 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.1 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.1 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/43.1 kB 162.5 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 41.0/43.1 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.1/43.1 kB 209.1 kB/s eta 0:00:00\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash>=3.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.8->langchain-groq)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Using cached langchain_groq-1.1.2-py3-none-any.whl (19 kB)\n",
      "Using cached groq-0.37.1-py3-none-any.whl (137 kB)\n",
      "Using cached langchain_core-1.2.9-py3-none-any.whl (496 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.7.0-py3-none-any.whl (321 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.7/2.0 MB 15.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.7 MB/s eta 0:00:00\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 158.8/158.8 kB 9.3 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
      "Using cached uuid_utils-0.14.0-cp39-abi3-win_amd64.whl (182 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.7-cp311-cp311-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/124.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 124.9/124.9 kB 7.2 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "   ---------------------------------------- 0.0/506.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 506.2/506.2 kB 31.0 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "   ---------------------------------------- 0.0/107.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.0/107.0 kB 6.0 MB/s eta 0:00:00\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Installing collected packages: zstandard, xxhash, uuid-utils, urllib3, typing-inspection, tenacity, sniffio, pyyaml, pydantic-core, orjson, jsonpointer, idna, h11, distro, charset_normalizer, certifi, annotated-types, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, langsmith, groq, langchain-core, langchain-groq\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.1 certifi-2026.1.4 charset_normalizer-3.4.4 distro-1.9.0 groq-0.37.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-1.2.9 langchain-groq-1.1.2 langsmith-0.7.0 orjson-3.11.7 pydantic-2.12.5 pydantic-core-2.41.5 pyyaml-6.0.3 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.4 typing-inspection-0.4.2 urllib3-2.6.3 uuid-utils-0.14.0 xxhash-3.6.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc2f2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-1.2.9-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.9 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain) (1.2.9)\n",
      "Collecting langgraph<1.1.0,>=1.0.7 (from langchain)\n",
      "  Using cached langgraph-1.0.8-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (0.7.0)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (26.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (9.1.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (0.14.0)\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Using cached langgraph_sdk-0.3.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.9->langchain) (3.0.0)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
      "  Downloading ormsgpack-1.12.2-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jahna\\onedrive\\desktop\\eeg+mri\\epilepsynexus\\venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (2.6.3)\n",
      "Using cached langchain-1.2.9-py3-none-any.whl (111 kB)\n",
      "Using cached langgraph-1.0.8-py3-none-any.whl (158 kB)\n",
      "Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
      "Using cached langgraph_sdk-0.3.4-py3-none-any.whl (67 kB)\n",
      "Downloading ormsgpack-1.12.2-cp311-cp311-win_amd64.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.2 kB ? eta -:--:--\n",
      "   ---------- ---------------------------- 30.7/117.2 kB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 117.2/117.2 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "Successfully installed langchain-1.2.9 langgraph-1.0.8 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.7 langgraph-sdk-0.3.4 ormsgpack-1.12.2\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install langchain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4079081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "# from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from graph import EpilepsyState\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56bbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model=\"llama-3.1-8b-instant\",\n",
    "#     api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "#     temperature=0.1,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aefc3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate(\n",
    "#     template=open(\"prompts/mri_eeg_fusion.txt\").read(),\n",
    "#     input_variables=[\n",
    "#         \"mri_epilepsy_label\",\n",
    "#         \"mri_confidence\",\n",
    "#         \"seizure_phase\",\n",
    "#         \"seizure_type\",\n",
    "#     ],\n",
    "# )\n",
    "from pathlib import Path\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "BASE_DIR = Path.cwd()  # EpilepsyNexus\n",
    "prompt_path = BASE_DIR / \"prompts\" / \"mri_eeg_combiner_prompt.txt\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_path.read_text(encoding=\"utf-8\"),\n",
    "    input_variables=[\n",
    "        \"mri_epilepsy_label\",\n",
    "        \"mri_confidence\",\n",
    "        \"seizure_phase\",\n",
    "        \"seizure_type\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c891096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def mri_eeg_fusion_node(state: EpilepsyState) -> EpilepsyState:\n",
    "    \"\"\"\n",
    "    Combines MRI and EEG classifier outputs using Groq LLM.\n",
    "    Produces epilepsy_presence + fusion explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- Read from state ----------\n",
    "    inputs = {\n",
    "        \"mri_epilepsy_label\": state.mri_epilepsy_label,\n",
    "        \"mri_confidence\": state.mri_confidence,\n",
    "        \"seizure_phase\": state.seizure_phase,\n",
    "        \"seizure_type\": state.seizure_type,\n",
    "    }\n",
    "\n",
    "    # ---------- Run LLM ----------\n",
    "    response = llm.invoke(prompt.format(**inputs))\n",
    "\n",
    "    # ---------- Parse JSON safely ----------\n",
    "    try:\n",
    "        output = json.loads(response.content)\n",
    "    except json.JSONDecodeError:\n",
    "        state.epilepsy_presence = \"uncertain\"\n",
    "        state.fusion_explanation = (\n",
    "            \"Fusion agent could not reliably combine MRI and EEG findings.\"\n",
    "        )\n",
    "        return state\n",
    "\n",
    "    # ---------- Write back to state ----------\n",
    "    state.epilepsy_presence = output.get(\"epilepsy_presence\")\n",
    "    state.seizure_phase = output.get(\"seizure_phase\")\n",
    "    state.seizure_type = output.get(\"seizure_type\")\n",
    "    state.fusion_explanation = output.get(\"fusion_explanation\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a531354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a medical AI assistant for epilepsy analysis.\n",
      "\n",
      "STRICT RULES:\n",
      "- Do NOT diagnose.\n",
      "- Do NOT recommend medication or treatment.\n",
      "- Do NOT give probabilities unless provided.\n",
      "- Only reason based on the given MRI and EEG outputs.\n",
      "- If evidence is insufficient or conflicting, say \"uncertain\".\n",
      "\n",
      "INPUTS:\n",
      "\n",
      "MRI Result:\n",
      "- Classification: Temporal Lobe Epilepsy\n",
      "- Confidence: 0.92\n",
      "\n",
      "EEG Result:\n",
      "- Seizure Phase: Ictal\n",
      "- Seizure Type: Focal seizure\n",
      "\n",
      "TASK:\n",
      "1. Decide epilepsy_presence as one of:\n",
      "   - \"yes\"\n",
      "   - \"no\"\n",
      "   - \"uncertain\"\n",
      "\n",
      "2. Keep seizure_phase and seizure_type ONLY if epilepsy_presence is \"yes\".\n",
      "   Otherwise, return \"not_applicable\".\n",
      "\n",
      "3. Write a concise medical fusion explanation\n",
      "   explaining how MRI and EEG findings relate.\n",
      "\n",
      "OUTPUT FORMAT (STRICT JSON):\n",
      "{\n",
      "  \"epilepsy_presence\": \"\",\n",
      "  \"seizure_phase\": \"\",\n",
      "  \"seizure_type\": \"\",\n",
      "  \"fusion_explanation\": \"\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_prompt = prompt.format(\n",
    "    mri_epilepsy_label=\"Temporal Lobe Epilepsy\",\n",
    "    mri_confidence=\"0.92\",\n",
    "    seizure_phase=\"Ictal\",\n",
    "    seizure_type=\"Focal seizure\"\n",
    ")\n",
    "\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4253b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a medical AI assistant for epilepsy analysis.\n",
      "\n",
      "STRICT RULES:\n",
      "- Do NOT diagnose.\n",
      "- Do NOT recommend medication or treatment.\n",
      "- Do NOT give probabilities unless provided.\n",
      "- Only reason based on the given MRI and EEG outputs.\n",
      "- If evidence is insufficient or conflicting, say \"uncertain\".\n",
      "\n",
      "INPUT\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d97a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = EpilepsyState(\n",
    "    mri_epilepsy_label=\"epilepsy\",\n",
    "    mri_confidence=0.93,\n",
    "    seizure_phase=\"ictal\",\n",
    "    seizure_type=\"focal\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdda6d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"mri_image_path\": null,\n",
      "    \"eeg_text_file_path\": null,\n",
      "    \"mri_epilepsy_label\": \"epilepsy\",\n",
      "    \"mri_confidence\": 0.93,\n",
      "    \"seizure_phase\": \"ictal\",\n",
      "    \"seizure_type\": \"focal\",\n",
      "    \"epilepsy_presence\": \"yes\",\n",
      "    \"fusion_explanation\": \"The MRI classification of epilepsy with high confidence (0.93) supports the presence of epilepsy. The EEG result indicating an ictal seizure phase and focal seizure type further confirms the diagnosis, suggesting a localized seizure activity consistent with epilepsy.\",\n",
      "    \"medical_context\": null,\n",
      "    \"neuro_diagnostic_report\": null,\n",
      "    \"patient_explanation\": null,\n",
      "    \"safety_passed\": false,\n",
      "    \"safety_notes\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "state = mri_eeg_fusion_node(state)\n",
    "\n",
    "\n",
    "print(json.dumps(state.model_dump(), indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad75bafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jahna\\OneDrive\\Desktop\\eeg+mri\\EpilepsyNexus\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(PROJECT_ROOT)\n",
    "\n",
    "from graph import EpilepsyState\n",
    "from llms.groq_llm import get_groq_llm\n",
    "\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent  \n",
    "prompt_path = PROJECT_ROOT / \"prompts\" / \"neuro_diagnostic_report_prompt.txt\"\n",
    "with open(prompt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "\n",
    "llm = get_groq_llm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
